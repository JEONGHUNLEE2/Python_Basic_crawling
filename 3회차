--------------------------리마인드
1. 라이브러리 불러오기 
2. 브라우저 열기 <-- chromedriver.exe / chromedrier
3. 웹페이지 접속 <-- browser.get(url)
4. 내가 원하는 정보가 있는지 확인
5. 정보가 있다면 --> browser.page_source 데이터 다운받기
6. 수집하고자 하는 정보 찾기 BeautifulSoup, select()
    - soup.select('태그정보')  -> "태그정보에 해당하는 모든 태그 찾아줘"
    - soup.select('태그명')     ex) soup.select('span')
    - soup.select('.class속성값') ex) soup.select('.presenter')
    - soup.select('태그명.class속성값')
    - soup.select('#id속성값')  ex) soup.select('#weeks1')
    - soup.select('상위태그정보 > 하위태그정보(자식)')   ex) soup.select('p > span')
    - soup.select('상위태그정보 하위태그정보(자손)') -> 자식을 포함한, 하위태그를 찾아줘 
        soup.select('p>a>span') --> "p태그 바로 아래에 a태그 바로 아래에 span 태그 다 찾아줘"
        soup.select('p span')   --> "p태그      아래에 있는              span 태그 다 찾아줘" // 굳이 안써도됌?흘려서 듣기

7. 태그 --> 내가 원하는 값만 선택
    - tag.text : "화면에 보이는 부분 / 태그 기호 앞뒤로 다 없앤거..."
    - tag['속성명'] : "태그에서 속성의 값" --> ex) tag['href']   <a href = "www.naver.com">자세히보기</a>
8. 리스트 저장
    - "리스트에 리스트 형태로.."  --> 행 / 열 맞춰서
9. 엑셀 저장
    - import pandas as pd
    - pd.DataFrame()
    - .to_excel('파일명.xlsx')
    
----------------------------------------------------------------------------------------------------------------------
