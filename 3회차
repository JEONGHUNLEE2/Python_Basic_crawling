--------------------------리마인드
1. 라이브러리 불러오기 
2. 브라우저 열기 <-- chromedriver.exe / chromedrier
3. 웹페이지 접속 <-- browser.get(url)
4. 내가 원하는 정보가 있는지 확인
5. 정보가 있다면 --> browser.page_source 데이터 다운받기
6. 수집하고자 하는 정보 찾기 BeautifulSoup, select()
    - soup.select('태그정보')  -> "태그정보에 해당하는 모든 태그 찾아줘"
    - soup.select('태그명')     ex) soup.select('span')
    - soup.select('.class속성값') ex) soup.select('.presenter')
    - soup.select('태그명.class속성값')
    - soup.select('#id속성값')  ex) soup.select('#weeks1')
    - soup.select('상위태그정보 > 하위태그정보(자식)')   ex) soup.select('p > span')
    - soup.select('상위태그정보 하위태그정보(자손)') -> 자식을 포함한, 하위태그를 찾아줘 
        soup.select('p>a>span') --> "p태그 바로 아래에 a태그 바로 아래에 span 태그 다 찾아줘"
        soup.select('p span')   --> "p태그      아래에 있는              span 태그 다 찾아줘" // 굳이 안써도됌?흘려서 듣기

7. 태그 --> 내가 원하는 값만 선택
    - tag.text : "화면에 보이는 부분 / 태그 기호 앞뒤로 다 없앤거..."
    - tag['속성명'] : "태그에서 속성의 값" --> ex) tag['href']   <a href = "www.naver.com">자세히보기</a>
8. 리스트 저장
    - "리스트에 리스트 형태로.."  --> 행 / 열 맞춰서
9. 엑셀 저장
    - import pandas as pd
    - pd.DataFrame()
    - .to_excel('파일명.xlsx')
    
----------------------------------------------------------------------------------------------------------------------
from selenium import webdriver
from bs4 import BeautifulSoup

browser = webdriver.Chrome('c:/informs/chromedriver.exe')

results = []

url = "https://youtube-rank.com/board/bbs/board.php?bo_table=youtube&page=1"
browser.get(url)

html = browser.page_source
soup = BeautifulSoup(html,'html.parser') 
channel_list = soup.select('form > table > tbody > tr') 

for channel in channel_list :
    
    title = channel.select('h1 > a')[0].text.strip()
    category = channel.select('p.category')[0].text.strip()
    subscriber = channel.select('td.subscriber_cnt')[0].text.strip()
    view = channel.select('td.view_cnt')[0].text.strip()
    video = channel.select('td.video_cnt')[0].text.strip()
    
    data = [title, category,subscriber, view, video]
    #print(data)
    results.append(data)
    
import pandas as pd
df = pd.DataFrame(results) 
df

df.columns = ['채널명','카테고리','구독자수','조회수','영상수']
df

df.to_excel('./1페이지크롤링2.xlsx', index = False)
#문자에서 숫자로 바꾸는거 찾아보기 

--------------------------------------------------------------완전 정리
from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd
import time #쉬게 해주는 함수
import random #랜덤하게 숫자 뱉는거

browser = webdriver.Chrome('c:/informs/chromedriver.exe')

results = []

page = 6
#page_list = [1,2,3,4,5...]
#[0:11]은 옆에 집합이 있어야함. ex) [01,13,3,3,3,4,,5,,,6,6,6][0:5] 이런식으로 
page_list = range(1,11)

for page in page_list:
    
#url = "https://youtube-rank.com/board/bbs/board.php?bo_table=youtube&page=3"
    url = f"https://youtube-rank.com/board/bbs/board.php?bo_table=youtube&page={page}"
    browser.get(url)
    #몇 초 기다려줘.....(접속~page_source 받기  사이에.....)
    time.sleep(2) #이렇게 하면 서버에서 차단될 수도 있음
    
    html = browser.page_source
    soup = BeautifulSoup(html,'html.parser') 
    channel_list = soup.select('form > table > tbody > tr') 

    for channel in channel_list :

        title = channel.select('h1 > a')[0].text.strip()
        category = channel.select('p.category')[0].text.strip()
        subscriber = channel.select('td.subscriber_cnt')[0].text.strip()
        view = channel.select('td.view_cnt')[0].text.strip()
        video = channel.select('td.video_cnt')[0].text.strip()

        data = [title, category,subscriber, view, video]
        #print(data)
        results.append(data)
        
#엑셀저장하기
df = pd.DataFrame(results) 
df.columns = ['채널명','카테고리','구독자수','조회수','영상수']
#filename = f'./유튜브채널랭크_Top{len(results)}.xlsx'
filename = f'유튜브채널랭크_Top{len(results)}.xlsx'
df.to_excel(filename, index = False)
